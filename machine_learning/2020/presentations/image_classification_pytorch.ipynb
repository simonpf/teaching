{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Image classification in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The MNIST dataset\n",
    "- MNIST handwritten digits dataset:\n",
    "    - Classification task with 10 classes\n",
    "    - Very popular benchmark dataset\n",
    "    \n",
    "![MNIST digits](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- dataset available in `pytorch` through `torchvision.datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "data = MNIST(\"./data\",\n",
    "             train=True,\n",
    "             download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Examples images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    ax = axs[i // 5, i % 5]\n",
    "    index = np.random.randint(0, len(data))\n",
    "    x, y = data[index]\n",
    "    ax.imshow(x, cmap=\"Greys\")\n",
    "    ax.set_title(\"Label = {}\".format(y))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Raw input data\n",
    "\n",
    "- Raw data is loaded as image object\n",
    "- Need as `torch.tensor` to use in `pytorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x, y = data[0]\n",
    "print(\"Type of x is:\", type(x))\n",
    "plt.imshow(x, cmap=\"Greys\")\n",
    "cb = plt.colorbar(label = \"pixel values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Transformed input data, pt. 1\n",
    "\n",
    "- Use a transformation object to transform `PIL Image` to\n",
    "  `pytorch` tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "transform = ToTensor()\n",
    "x_t = transform(x)\n",
    "print(\"Type of x_t: \", type(x_t))\n",
    "\n",
    "plt.imshow(x_t[0], cmap=\"Greys\")\n",
    "cb = plt.colorbar(label = \"pixel values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Transformed input data, pt. 2  \n",
    "  \n",
    "- It's usually a good idea to normalize input data\n",
    "- Use composition of two transformations to:\n",
    "    - Transform image to tensor\n",
    "    - Normalize pixel values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "transform = Compose([ToTensor(),\n",
    "                     Normalize([0.5], [0.5])])\n",
    "x_t = transform(x)\n",
    "print(\"Shape of x_t: \", x_t.size())\n",
    "\n",
    "plt.imshow(x_t[0], cmap=\"Greys\")\n",
    "cb = plt.colorbar(label = \"pixel values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Apply transforms to dataset\n",
    "\n",
    "- Provide transformations as `transform` argument to\n",
    "  dataset constructor to apply them automatically to\n",
    "  every image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "transform = Compose([ToTensor(),\n",
    "                     Normalize([0.5], [0.5])])\n",
    "data = MNIST(\"./data\",\n",
    "             train=True,\n",
    "             download=True,\n",
    "             transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data preparation\n",
    "- Split dataset into training and validation part\n",
    "- Create data loaders to group samples into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Split into training and validation part\n",
    "n_train = int(0.8 * len(data))\n",
    "n_val = len(data) - n_train\n",
    "training_data, validation_data = random_split(data, [n_train, n_val])\n",
    "\n",
    "# Organize data into batches\n",
    "training_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(validation_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Dataloader class\n",
    "- Groups input tensors into a single tensor containing a batch of samples\n",
    "- Input image has shape $1 \\times 28 \\times 28$\n",
    "    - 1 color channel (greyscale), 2 channels for horizontal and vertical image dimensions\n",
    "- Batched data has shape $32 \\times 1 \\times 28 \\times 28$\n",
    "\n",
    "> **Note**: Standard convention in `pytorch` is *channels first*: Dimension corresponding to color comes before spatial dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_0, y_0 = next(iter(data))\n",
    "x_1, y_1 = next(iter(training_loader))\n",
    "print(\"Shape of x_0:\", x_0.size())\n",
    "print(\"Shape of x_1:\", x_1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Defining a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Typical approach\n",
    "\n",
    "- Define a model class that inherits from `nn.Module`\n",
    "- The `nn.Module` base class defines the general functionality that\n",
    "  `pytorch` from a neural network\n",
    "- Required:\n",
    "   - Call to base class constructor: `super().__init__()`\n",
    "   - `forward(...)` function that propagates input through network\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 output_size):\n",
    "        super().__init__()\n",
    "        ...\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ...\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Typical approach\n",
    "\n",
    "- Model class contains layers as attributes\n",
    "- The `nn.Module` class automatically keeps track of\n",
    "  the trainable parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size,  hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.flatten(1, -1)\n",
    "        y = self.fc1(x)\n",
    "        y = torch.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = torch.relu(y)\n",
    "        y = self.fc3(y)\n",
    "        y = torch.relu(y)\n",
    "        y = self.fc4(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Typical approach\n",
    "\n",
    "- To train a specific model you need to instantiate your model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fc = FullyConnected(input_size=28 * 28,\n",
    "                    hidden_size=128,\n",
    "                    output_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training loop\n",
    "- In `pytorch` you usually have an explicit training loop\n",
    "- Below is basically a copy from the function provided in HW4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(training_loader,\n",
    "                validation_loader,\n",
    "                model,\n",
    "                loss,\n",
    "                optimizer,\n",
    "                device):\n",
    "    \"\"\"\n",
    "    Train given model for one epoch and evaluate validation error.\n",
    "    Args:\n",
    "        training_loader: Iterable providing batched training data\n",
    "        validation_loader: Iterable providing batched validation data\n",
    "        loss: Loss function to minimize\n",
    "        optimizer: Optimizer to use to optimizer loss.\n",
    "        device: The torch device on which to run the calculations.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    training_loss = 0.0\n",
    "    n = len(training_loader)\n",
    "    \n",
    "    for i, (x, y) in enumerate(training_loader):\n",
    "        \n",
    "        # Set gradients to zero.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Move input to device\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Predict output, compute loss, perform optimizer step.\n",
    "        y_pred = model(x)\n",
    "        l = loss(y_pred, y)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss += l.item()\n",
    "        print(\"Batch ({} / {}): Loss {:.2f}\".format(i, n, l.item()), end=\"\\r\")\n",
    "        \n",
    "    training_loss /= n\n",
    "        \n",
    "    model.eval()\n",
    "    validation_loss = 0.0\n",
    "    n = len(validation_loader)\n",
    "    \n",
    "    for i, (x, y) in enumerate(validation_loader):\n",
    "        # Move input to device\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Predict output, compute loss, perform optimizer step.\n",
    "        y_pred = model(x)\n",
    "        l = loss(y_pred, y)\n",
    "        \n",
    "        validation_loss += l.item()\n",
    "    validation_loss /= n\n",
    "    \n",
    "    model.to(torch.device(\"cpu\"))\n",
    "    \n",
    "    return (training_loss, validation_loss)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Choosing the loss function\n",
    "\n",
    "- Note that we don't apply an activation function to the network outputs\n",
    "- Instead of predicting probabilites directly, we predict **logits** (Unnormalized, log-probabilities)\n",
    "  for each class\n",
    "- This has numerical advantages (as explained in Sec. 6.2.2.1 and 6.2.2.2 of the [deep learning book](https://www.deeplearningbook.org/contents/mlp.html).)\n",
    "- `pytorch` has specific loss functions that combine softmax or sigmoid and negative log-likelihood (NLL) loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training the model\n",
    "\n",
    "- This is now straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(fc.parameters())\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "for i in range(3):\n",
    "    tl, vl = train_epoch(training_loader, validation_loader, fc, loss, optimizer, device)\n",
    "    print(\"Epoch {}: Validation loss = {}\".format(i + 1, vl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CNN Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Another way of defining networks\n",
    "\n",
    "- Networks with simple linear structure can be defined using the `nn.Sequential` class\n",
    "- Each transformation (convolution, activation function, pooling, flatten) defined by a layer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cnn = nn.Sequential(nn.Conv2d(1, 32, 3),      # 32 x 26 x 26\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(2, 2),       # 32 x 13 x 13\n",
    "                    nn.Conv2d(32, 64, 3),     # 64 x 11 x 11\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(2, 2),       # 64 x 5 x 5\n",
    "                    nn.Flatten(1, -1),        # 64 * 5 * 5 \n",
    "                    nn.Linear(25 * 64, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(256, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters())\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "for i in range(3):\n",
    "    tl, vl = train_epoch(training_loader, validation_loader, cnn, loss, optimizer, device)\n",
    "    print(\"Epoch {}: Validation loss = {}\".format(i + 1, vl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example results\n",
    "\n",
    "- Brief look at some samples from test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "transform = Compose([ToTensor(),\n",
    "                     Normalize([0.5], [0.5])])\n",
    "data = MNIST(\"./data\",\n",
    "             train=False,\n",
    "             download=True,\n",
    "             transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    ax = axs[i // 5, i % 5]\n",
    "    \n",
    "    index = np.random.randint(0, len(data))\n",
    "    x, y = data[index]\n",
    "    x = x.unsqueeze(dim=0)\n",
    "    y_pred = torch.argmax(torch.softmax(cnn(x), -1))\n",
    "    \n",
    "    ax.imshow(x[0, 0], cmap=\"Greys\")\n",
    "    ax.set_title(\"Predicted = {}, \\n True = {}\".format(y_pred, y))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
