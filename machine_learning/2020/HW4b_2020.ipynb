{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\qquad$ $\\qquad$$\\qquad$  **TDA 232 / DIT 381: Home Assignment 4, part 2 - Sequence learning  (10 points)** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$ **Goal: Time series prediction using recurrent neural networks**<br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Grader: Emilio, Simon** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                     **Due Date: 22/5** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Submitted by: Name, Personal no., email** <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General guidelines:\n",
    "* All solutions to theoretical and pratical problems must be submitted in this notebook, and equations should be formatted using LaTeX math-mode.\n",
    "* For each exercise part, add cells containing the requested text, code or figures into this notebook.\n",
    "* Your notebook should contain all required cell output, so that we don't have to execute the code. However, should we decide to, your notebook should run and reproduce the results up to stochastic variability. A good idea is to make sure it runs on Google Colab before submission.\n",
    "* **Submit your solutions as notebook file (`.ipynb`) and in HTML format (`.html`).** To export this notebook to HTML format click `File` $\\rightarrow$ `Download as` $\\rightarrow$ `HTML`.\n",
    "\n",
    "> **Note:** Training neural networks is computationally demanding and may take  time if you run it on your laptop. Running the code in Google Colab will likely be faster and you can even get access to a GPU.\n",
    "\n",
    "> **Note:** To enable GPU hardware accelartion in Google Colab, click the `Change runtime type` field in the `runtime` drop-down menu, then choose `GPU` under hardware acceleration.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/simonpf/teaching/blob/master/machine_learning/2020/HW4b_2020.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required software\n",
    "\n",
    "In addition to `numpy` and `matplotlib`, you will need to install the following Python packages for  this assignment:\n",
    "- `numpy`, `matplotlib`\n",
    "- `pytorch`: Installation instructions can be found on the [pytorch homepage](https://pytorch.org/get-started/locally/) (pre-installed in Google Colab)\n",
    "- `camels`: The data set we will be working with. To install it, run:\n",
    "\n",
    "```\n",
    "pip install camels\n",
    "\n",
    "```\n",
    "\n",
    "> **Note:** In Google Colab you can install packages using   `!pip  <package_name>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5, Part 2\n",
    "\n",
    "# Theoretical exercises\n",
    "\n",
    "## [Exercise 1, 3 points]\n",
    "\n",
    "Consider a RNN, which maps a sequence of inputs $\\mathbf{x}_0, \\mathbf{x}_1, \\ldots$ to a sequence of outputs $\\mathbf{y}_0, \\mathbf{y}_1, \\ldots$. At each step $t$, the hidden state $\\mathbf{h}_t$ and output $\\hat{\\mathbf{y}}_t$ of the RNN are computed using\n",
    "\\begin{align}\n",
    "  \\mathbf{h}_t &= \\tanh( \\mathbf{W}_{xh}\\ \\mathbf{x}_t + \\mathbf{W}_{hh} \\ \\mathbf{h}_{t -1}) \\\\\n",
    "  \\hat{\\mathbf{y}}_t &= \\mathbf{W}_{hy}\\ \\mathbf{h}_t\n",
    "\\end{align}\n",
    "  \n",
    "### 1, a) (1 Point)\n",
    "\n",
    "The RNN is applied to a sequence of two inputs $\\mathbf{x}_0, \\mathbf{x}_1$. Write down analytic expressions for the corresponding outputs $\\mathbf{y}_0, \\mathbf{y}_1$ assuming the initial hidden state to be the zero vector.\n",
    "\n",
    "### 1, b) (1 Point)\n",
    "\n",
    "Assume that the vectors $\\mathbf{x}_0, \\mathbf{x}_1$ have a length of 8, the hidden state $\\mathbf{h}_t$ a length of $16$ and the output vectors $\\hat{\\mathbf{y}}_0, \\hat{\\mathbf{y}}_1$ a length of 1. How many learnable parameters does the RNN described above have? How does this number depend on the length of the input sequence?\n",
    "\n",
    "### 1, c) (1 Point)\n",
    "\n",
    "Describe two diffculties that can occur when training RNNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical exercises\n",
    "\n",
    "In the practical part of the assignment you will use RNNs to predict the amount of water flowing in a stream or river, the so-called *streamflow*, from meteorological data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "The data that you will be using for the training comes from a scientific dataset named *Catchment Attributes and Meteorology for Large-sample Studies* (CAMELS). It is described in detail in the following paper:\n",
    "\n",
    "A. Newman; K. Sampson; M. P. Clark; A. Bock; R. J. Viger; D. Blodgett, 2014. A large-sample watershed-scale hydrometeorological dataset for the contiguous USA. Boulder, CO: UCAR/NCAR. https://dx.doi.org/10.5065/D6MW2F4D\n",
    "\n",
    "The dataset contains time series of streamflow combined with the most important *meteorological forcings* for the given river or stream. The forcing values describe the most important meteorological processes that determine the streamflow. The princpial forcing is of course precipitation, i.e. rain and snow, but also the temperature and strength of solar can indirectly influence the streamflow. These forcings have been aggregated over the drainage basin, which is the area upstream of the gauge measuring the streamflow in which precipitation will drain off into the river whose streamflow is being measured.\n",
    "\n",
    "A model that predicts the strength of the flow in a river from meteorological inputs is called a run-off model.  Important applications of run-off models are predicting floods or analysing the impact of climate change on the stream and its surroundings.\n",
    "\n",
    "In this exercise you will use the streamflow dataset to develop your own run-off model. For this you will use data from a single gauge, identified by the ID `13331500`. The plot below displays the location of the gauge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import camels\n",
    "\n",
    "gauge_id = 13331500\n",
    "camels.plot_basin(gauge_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `camels` package provides a Python interface for the streamflow data. Using the `camels.pytorch.Streamflow` class you can access the time series data directly as `pytorch` tensors.\n",
    "\n",
    "The available data spans the time range from 1980 to 2014. Of that, the first 26 years are used as training data, years 2006 to 2010  as validation data and years 2010 to 2014 as testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camels.pytorch import Streamflow\n",
    "training_data = Streamflow(gauge_id, \"training\")\n",
    "validation_data = Streamflow(gauge_id, \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below gives an overview over a period of three years from the training data. The first three panels show the six meteorological forcings that are the inputs for modeling the streamflow:\n",
    "- length of the day\n",
    "- strength of incoming solar radiation\n",
    "- precipitation\n",
    "- (water) vapor pressure, i.e. the amount of water vapor in the air\n",
    "- daily minimum temperature\n",
    "- daily maximum temperature\n",
    "\n",
    "The lowest panel shows the measured streamflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start = datetime(2000, 1, 1, hour=0)\n",
    "end = datetime(2003, 1, 1, hour=0)\n",
    "training_data.plot_overview(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exercise 1] (1 point) \n",
    "\n",
    "Describe any patterns you see in the time series of forcings and streamflow shown above. Provide a simple description of the physical processes that relate the forcings (input) to the streamflow (output)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing data\n",
    "\n",
    "The `Streamflow` dataset provides sequences of a length of 400 days of meteorological forcings and corresponding streamflows as samples. The `data_loader` member function can be used to instantiate `pytorch` dataloaders with a given batch size.\n",
    "\n",
    "> **Note 1:** Input and outputs in the dataset are all normalized to have mean 0 and standard deviation 1. For simplicity, we will from now on consider forcings and outputs in normalized units instead of the units given in the plot above.\n",
    "\n",
    "> **Note 2:** Pytorch expects tensors of sequences to have the elements in the sequence along the first dimension and the batch elements along the second. A tensor containing a batch of 8 samples from the `Streamflow` data thus\n",
    "has shape `(400, 8, 6)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = training_data.data_loader(batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exercise 2] (2 points)\n",
    "\n",
    "### 2, a) (1 point)\n",
    "\n",
    "Write a custom `torch.nn.Module` subclass that implements the basic RNN from theoretical exercise 1 **without using the predefined `nn.RNN` class provided by `pytorch`**. Include the bias terms for the mappings from input to hidden state, hidden state to hidden state, and hidden state to output. This means\n",
    "that for step $t$, the hidden state $h_t$ and output $\\hat{y}_t$ should be given by:\n",
    "\n",
    "\\begin{align}\n",
    "  h_t &= \\tanh( \\mathbf{W}_{hx}\\ x_t + \\theta_{hx} + \\mathbf{W}_{hh} \\ h_{t - 1} + \\theta_{hh}) \\\\\n",
    "  \\hat{y}_t &= \\mathbf{W}_{hy}\\ h_t + \\theta_y\n",
    "\\end{align}\n",
    "\n",
    "Make the size of the hidden state a parameter of the class constructor.\n",
    "\n",
    "\n",
    "> **Hint 1:** You can use `torch.nn.Linear` layers to implement the linear mappings between input, hidden state, and output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2, b) (1 point)\n",
    "\n",
    "Train an instance of your RNN model class using mean squared error (MSE) loss on the streamflow training data. For the hidden state, a size around $64$ is a suitable first choice.\n",
    "\n",
    "Monitor the validation loss by computing the MSE for a single predicted sequence of streamflows for the full validation time range. You can obtain the input and output tensors corresponding to the full validation range by calling the `get_range` member function of `validation_data`:\n",
    "\n",
    "```\n",
    "x,y = validation_data.get_range()\n",
    "```\n",
    "\n",
    "Plot training and validation losses.\n",
    "\n",
    "> **Hint 1:** To train your RNN you are free to use all available `pytorch` functionality. Particularly the [`torch.optim`](https://pytorch.org/docs/stable/optim.html) module can be of interest.\n",
    "\n",
    "> **Hint 2:** As baseline, training using the `Adam` optimizer with a learning rate of $10^{-3}$ for 40 epochs should give a significant reduction in training loss. The reduction in the validation will likely be much smaller.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exerise 3] (2 points)\n",
    "\n",
    "### 3, a) (2 points)\n",
    "\n",
    "Train a LSTM neural network on the streamflow data. The network should have at least one `LSTM` layer followed by fully-connected layer to map the hidden state to the output dimension.\n",
    "\n",
    "> **Hint 1**: Use the `torch.nn.LSTM` class to implement the LSTM layer.\n",
    "\n",
    "> **Hint 2:** Again, training using the `Adam` with a learning rate of $10^{-3}$ optimizer for 40 should give reasonable performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Exerise 4] (2 points)\n",
    "\n",
    "Evaluate all three models  on the test data. Make a plot with a panel for each of your models that shows predicted and true streamflow. Provide a table with mean absolute error, mean squared error and correlation coefficients. Describe main differences between the results for different models.\n",
    "\n",
    "> **Hint:** For plotting, you can use `test_data.data.index` to get the dates corresponding to the sequence returned by `test_data.get_range()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
