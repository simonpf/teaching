{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\qquad$ $\\qquad$$\\qquad$  **TDA 232 / DIT 381: Home Assignment 4, part 1 - Image classification (20 points)** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$ **Goal: Image classification using fully-connected and convolutional neural networks** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Grader: Emilio, Simon** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                     **Due Date: 22/5** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Submitted by: Name, Personal no., email** <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General guidelines:\n",
    "* All solutions to theoretical and pratical problems must be submitted in this notebook, and equations should be formatted using LaTeX math-mode.\n",
    "* For each exercise part, add cells containing the requested text, code or figures into this notebook.\n",
    "* Your notebook should contain all required cell output, so that we don't have to execute the code. However, should we decide to, your notebook should run and reproduce the results up to stochastic variability. A good idea is to make sure it runs on Google Colab before submission.\n",
    "* **Submit your solutions as notebook file (`.ipynb`) and in HTML format (`.html`).** To export this notebook to HTML format click `File` $\\rightarrow$ `Download as` $\\rightarrow$ `HTML`.\n",
    "\n",
    "> **Note:** Training neural networks is computationally demanding and may take  time if you run it on your laptop. Running the code in Google Colab will likely be faster and you can even get access to a GPU.\n",
    "\n",
    "> **Note:** To enable GPU hardware accelartion in Google Colab, click the `Change runtime type` field in the `runtime` drop-down menu, then choose `GPU` under hardware acceleration.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/simonpf/teaching/blob/master/machine_learning/2020/HW4a_2020.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required software\n",
    "\n",
    "For this assignment you will need to install the following Python packages:\n",
    "- `pytorch`: Installation instructions can be found on the [pytorch homepage](https://pytorch.org/get-started/locally/) (pre-installed in Google Colab)\n",
    "- `torchvision`: Typically installed with pytorch\n",
    "- `catsndogs`: The data set we will be working with. To install it, run:\n",
    "\n",
    "```\n",
    "pip install catsndogs\n",
    "\n",
    "```\n",
    "\n",
    "> **Note:** In Google Colab you can install packages using   `!pip  <package_name>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4, Part 1\n",
    "# Theoretical exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exercise 1: Backpropagation by hand, 1 point]\n",
    "\n",
    "Consider the simple feed-forward neural network depicted in the figure below. This network\n",
    "consists of an input layer $\\mathbf{y}_0 = \\mathbf{x}$ with 3 features,  one hidden layer\n",
    "with activations $\\mathbf{y}_1$ and a one-dimensional output layer with activations $\\mathbf{y}_2$.\n",
    "\n",
    "![Neural network illustration.](https://raw.githubusercontent.com/simonpf/teaching/master/machine_learning/2020/simple_nn.png)\n",
    "\n",
    "\n",
    "The activations of a layer $i$ are computed by applying a linear transformation given by the weight matrix\n",
    "$\\mathbf{W}_i$ to the input activations $\\mathbf{y}_{i - 1}$ producing the intermediate values $\\mathbf{z}_i$:\n",
    "\n",
    "$$\n",
    "z_{i : j} = \\sum_k W_{i:j, k} y_{i - 1:k} \\\\\n",
    "$$\n",
    "\n",
    "This is followed by the element-wise application of the layers'\n",
    "activation function $f_i$ to the intermediate values $\\mathbf{z}_i$:\n",
    "\n",
    "$$\n",
    "y_{i:j} = f_i (z_{i:j})\n",
    "$$\n",
    "\n",
    "> **Note:** The notation here uses '$:$' to separate layer from element indices. $W_{i:j,k}$ thus refers to the element in row $j$ and column $k$ in the weigth matrix $\\mathbf{W}_i$ of the $i$th layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1, a)\n",
    "\n",
    "Given the derivative of an error term $E$ with respect to the activation of the output neuron \n",
    "$\\frac{dE}{dy_{2:0}}$, derive expressions for the derivatives of the error term with respect to the weights\n",
    "$W_{i:j,k}$ and activations $y_{i:j}$ of the remaining layers of the network.\n",
    "\n",
    "To simplify the results, you are encouraged to reuse derivatives you have already computeds in the expressions for the  downstream derivatives.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{dE}{dW_{2:i, j}} = \\: ? \\\\\n",
    "\\frac{dE}{dy_{1:j}} = \\: ? \\\\\n",
    "\\frac{dE}{dW_{1:i, j}} = \\: ? \\\\\n",
    "\\frac{dE}{dy_{0:j}} = \\: ? \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If your calculations are correct, you should see that you can express the derivatives of the error function \n",
    "around a given layer in the network using the derivatives from the next higher layer. This yields a simple\n",
    "recipe to successively compute the gradients in a feed forward neural network by starting at the last layer and\n",
    "then computing the gradients layer-by-layer as you move backwards through the network. This method is commonly\n",
    "referred to as **backpropagation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exercise 2: Loss function for binary classification, 1 point]\n",
    "\n",
    "Assume that your task is to predict a binary class variable $Y \\in \\{0, 1\\}$ conditional on some input $X$ using a neural network. To do so you want to train a network to predict the probability $p$ of a bernoulli distribution:\n",
    "\n",
    "\\begin{align}\n",
    "P(Y | X) \\sim \\text{Bernoulli}(p = f(x)),\n",
    "\\end{align}\n",
    "\n",
    "where $f$ represents the function to be learned by the neural network.\n",
    "\n",
    "### 2, a)\n",
    "\n",
    "Given independent pairs of samples $(x_1,  y_1), \\ldots, (x_n, y_n)$ show that minimizing the binary cross entropy loss\n",
    "\n",
    "\\begin{align}\n",
    "BCE = -\\frac{1}{n}\\sum_{i = 1}^n (1 - y)\\ \\log(1 - f(x)) + y\\ \\log(f(x))\n",
    "\\end{align}\n",
    "\n",
    "maximizes the likelihood of the data.\n",
    "\n",
    "> Hint: Note that the probability function of Bernoulli distributed variable $Y \\sim \\text{Bernoulli}(p)$ can be written $P(Y = y) = p^y\\ (1- p)^{(1-y)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exercise 3: Counting parameters in networks, 1 point]\n",
    "\n",
    "### 3, a)\n",
    "Imagine you apply a two layer fully connected network to a 28x28 rgb image. The hidden layer has dimension 256 and the output is of size 10. How many parameters are necessary? Include the bias parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3, b)\n",
    "\n",
    "Apply the following network to the same image, how many parameters are needed? Include bias parameters. Show your calculations.\n",
    "\n",
    "* Convolutional layer with 8 3x3 filters (stride 1).\n",
    "\n",
    "* Max pooling layer (2x2) (stride 2).\n",
    "\n",
    "* Convolutional layer with 16 3x3 filter (stride 1).\n",
    "\n",
    "* Fully connected layer to ouput of size 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Excercise 4: Calculating output dimensions of a convolutional layer, 1 point]\n",
    "\n",
    "Assume you apply a convolutional layer with 8 3x3 filters (stride 1) on a rgb 28x13 image. What will the dimensions of the output be (assuming no padding is done in the convolution)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Excercise 5: Applying a filter to an image, 1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\text{Image:} \n",
    "\\begin{bmatrix}2 & 2 & 1 & 2 \\\\\n",
    "               -2 & -2 & -1 & 1 \\\\\n",
    "               1 & 1 & 2 & 1 \\\\\n",
    "               1 & 1 & 3 & 1 \n",
    "\\end{bmatrix}\n",
    "\\ \\ \n",
    "\\text{Filter:}\n",
    "\\begin{bmatrix}1 & 1\n",
    "\\\\-1 & -1\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "Convolve the filter over the image and apply ReLU, use a stride of 2 with a bias of -2. Try to give an explanation for the output, what is the filter detecting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical exercises\n",
    "\n",
    "In this practical exercise, you will develop a classification algorithm that predicts whether an image contains a cat or a dog. You wil do this using the `pytorch` deep learning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "The data that you will be using in this exercise consists of images of cats and dogs. The dataset is available through the `catsndogs` Python package. The package automatically downloads the data and provides access to the image files in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catsndogs.training import cats, dogs # The lists of cat and dog images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, a few examples of the images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "f, axs = plt.subplots(2, 4, figsize = (8, 4))\n",
    "for i in range(4):\n",
    "    img = np.random.choice(cats)\n",
    "    ax = axs[0, i]\n",
    "    ax.set_title(\"A Cat\")\n",
    "    ax.imshow(Image.open(img))\n",
    "for i in range(4):\n",
    "    img = np.random.choice(dogs)\n",
    "    ax = axs[1, i]\n",
    "    ax.set_title(\"A Dog\")\n",
    "    ax.imshow(Image.open(img))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with pytorch\n",
    "\n",
    "The following part provides a brief introduction to the fundamentals of `pytorch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why pytorch?\n",
    "\n",
    "As most other popular deep learning frameworks, `pytorch` provides the following features:\n",
    "\n",
    "- automatic differentiation,\n",
    "- GPU support,\n",
    "- flexible composition of neural network models,\n",
    "- numerous pre-defined network components and optimization methods.\n",
    "\n",
    "Pytorch strikes a good balance between flexibility, usability and performance, making it well suited for an introductory exercise as this one. There of course exist quite a few alternative frameworks, but the general concepts that you will learn in this exercise will apply also for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing documentation\n",
    "\n",
    "Note that you can access source code documentation from inside the jupyter notebook using `?` and the `help` function. Documentation of the different torch modules can be found on the [pytorch home page](https://pytorch.org/docs/stable/index.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "help(torch.tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors\n",
    "\n",
    "Tensors are a fundamental concept of `pytorch`, as well as most other deep learning frameworks. A tensor  designates a collection of elements that are organized on a multi-dimensional grid. You may think of them as a generalization of vectors or matrices: The elements in a vector are organized along 1 dimension, whereas in a matrix they are organized along 2 dimensions.\n",
    "\n",
    "A typical application of tensors is to hold images. As an example, we can load an image of a dog into a `torch.tensor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "image_name = np.random.choice(dogs)\n",
    "dog = to_tensor(Image.open(image_name))\n",
    "print(\"The size of 'dog' is:\", dog.size())\n",
    "dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It becomes interesting when we start applying mathematical operations to tensors. For example we can compute the average of a cat and a dog. Note that all common mathematical operators (`+`, `-` `*`, `**`, ...) are defined on tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = np.random.choice(cats)\n",
    "cat = to_tensor(Image.open(image_name))\n",
    "plt.imshow(to_pil_image(0.5 * (cat + dog)))\n",
    "plt.title(\"A cat/dog average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common tensor operations\n",
    "\n",
    "There are many operations available on tensors and most of them follow the names used in `numpy`. In general, you can expect there to be an operation for most tasks at hand, so make sure you check the `pytorch` documentation search engine before you start cooking up something on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ones = torch.ones(10, 10)\n",
    "zeros = torch.zeros(10, 10)\n",
    "rand = torch.randn(10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand1 = torch.add(ones, rand)\n",
    "p = torch.sigmoid(rand)\n",
    "exp = torch.exp(rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type conversions\n",
    "\n",
    "As with `numpy.ndarray`s, the elements in a `torch.tensor` can have different data types. You can convert between different data types using the `to` member function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The data type of p:\", p.dtype)\n",
    "p_short = p.to(torch.short)\n",
    "print(\"The data type of p_short:\", p_short.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML tasks you typically want to use [single-precision floating point numbers](https://en.wikipedia.org/wiki/Single-precision_floating-point_format) (`torch.float32`). In general you will not have to worry too much about the data type, however, older versions of `pytorch` will throw errors when operations are performed on tensors with different numeric types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p + p_short # Fails on older version of pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = p + p_short.float() # short for p_double.to(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion from and to numpy arrays\n",
    "\n",
    "numpy arrays can be converted directly to pytorch tensors using the `torch.tensor` function.\n",
    "\n",
    "Converting `pytorch` tensors to numpy arrays can be done using the `numpy()` member function. If `pytorch` tracks the gradient of a tensor, then you will also need to call the `detach()` member function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_numpy = np.random.rand(2, 2)\n",
    "t = torch.tensor(t_numpy)\n",
    "print(\"Type of t:\", type(t_numpy))\n",
    "print(\"Type of t_pytorch:\", type(t))\n",
    "print(\"Type of t_pytorch.numpy():\", type(t.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.requires_grad = True\n",
    "#t.numpy() # Doesn't work\n",
    "t.detach().numpy() # Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic differentiation\n",
    "\n",
    "One of the core strengths of pytorch is that it let's you copute complex mathematical operations on tensors and compute their derivatives. Remember, that this is an important part of training neural networks: In order to minimize the loss function using gradient descent, it is of course required to first compute the gradients. Luckily, `pytorch`'s `autograd` module can take care of all the complicated calculations that are required to compute the gradients of neural networks.\n",
    "\n",
    "Computing gradients w.r.t to a given tensor involves the following steps:\n",
    "1. Create a tensor and set the `requires_grad` attribute to `True`,\n",
    "2. apply mathematical operations,\n",
    "3. call the `backward()` function of the result tensor to compute the gradients.\n",
    "\n",
    "> *Note:* Step 1 is not required for parameters of networks, whose gradients are computed by default when the model is in training mode.\n",
    "\n",
    "As an example, take the following operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-4, 4, 101, requires_grad=True)\n",
    "y = torch.sigmoid(x)\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "dzdx = x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1)\n",
    "ax.plot(x.detach().numpy(),\n",
    "        y.detach().numpy(),\n",
    "        label = \"$\\sigma(x)$\")\n",
    "ax.plot(x.detach().numpy(),\n",
    "        dzdx.numpy(),\n",
    "        label = \"$?(x)$\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Exercise 1: Derivatives of activation functions, 1 point] \n",
    "\n",
    "Write down analytical expressions for the function $\\sigma(x)$ and $?$ shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU acceleration\n",
    "\n",
    "Training complex networks is a computationally demanding task. To shorten training times, caluclations are typically performed on specialized hardware that was traditionally used to render 3D graphics on computers, so called graphic processing units (GPUs) or graphic cards . GPUs are in general more efficient in performing  highly-parallel computational tasks than CPUs, which are the chips that perform all 'standard' calculations in a PC. In `pytorch`, all oprations on tensors can be performed on a GPU using NVIDIA's CUDA computing platforms (https://en.wikipedia.org/wiki/CUDA).\n",
    "\n",
    "The different processors that can be used for calculations, i.e. CPU or GPU, are represented in `pytorch` as devices. Each tensor has an associated device on which its data is located.\n",
    "The default device is represented by `torch.device(\"cpu\")`. By default, all calculations are executed on the CPU.  In order to be able to perform calculations on a tensor, you need to move its data to the GPU's memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First check if CUDA is available.\n",
    "print(torch.cuda.is_available())\n",
    "cuda = torch.device(\"cuda\")\n",
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will perform a quick demonstration of how much faster matrix multiplication becomes when executed on a  GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.rand(512, 512)\n",
    "def matmul_cpu():\n",
    "    result = W\n",
    "    for i in range(10):\n",
    "        result = torch.matmul(W, result)\n",
    "    return result\n",
    "        \n",
    "%time matmul_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_cuda = W.to(cuda)\n",
    "\n",
    "def matmul_gpu():\n",
    "    result = W_cuda\n",
    "    for i in range(10):\n",
    "        result = torch.matmul(W_cuda, result)\n",
    "    return result\n",
    "        \n",
    "matmul_gpu() # First time using GPU can incur some overhead.\n",
    "%time matmul_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%time` command displays CPU and Wall time for the execution of the two functions. The CPU time is split up in `user` time, which is the time spent executing only your code, and `sys` time, which is the time spent executing system kernel code required for example to load data from disk. Note that the CPU time is computed per core, so when your code runs on multiple cores the resulting CPU time is the sum of the time each core spends computing.\n",
    "\n",
    "The wall time shows the total time that it took to execute the function. Since CPU time is calculated per core, the wall time can actually be lower than the CPU time for code that is executed on multiple CPUs in parallel.\n",
    "\n",
    "To compare the absolute execution time for the two functions it is therefore most meaningful to compare the displayed wall times. As you should see from them, calculating the matrix power on the GPU is substantially faster than calculating it on the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "To train a network on the `catsndogs` dataset, we need to load the images into tensors. The `catsndogs.training` module has an attribute `folder`, which points to the root folder containing the training data. The root folder contains a `cat` and a `dog` folder which holds the images of cats and dogs, respectively.\n",
    "\n",
    "\n",
    "Using the `torchvision.datasets.ImageFolder` class, data that is organized in a folder structure like this can be turned directly into a dataset for training ML algorithms. The dataset provides access to the images as input and as an integer representations of the class labels as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catsndogs.training import folder\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "images = ImageFolder(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load a sample from the training data by indexing the `images` object, which will return a tuple `(image, label)` containing the loaded image and corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = images[0]\n",
    "plt.imshow(image)\n",
    "print(\"The type of image is:\", type(image))\n",
    "print(\"The label is:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as the code above shows, the type of the loaded image is a `PIL` image and not a tensor. To automatically transform the loaded image into a tensor, you can make use of the `transformation` parameter of the `ImageFolder` class.\n",
    "\n",
    "The cell below adds a composition of two transforms to the dataset. The two transforms are applied sequentially to the image object that would otherwise be returned from the dataset. The first transform turns the image into a torch tensor and the second transform normalizes the image values so that they lie in the range $[-1, 1]$.\n",
    "\n",
    "> Note: Input data that is not centered around zero can cause convergence problems during training, so it is usually a good idea to normalize input data to a range centered around 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "transform = Compose([ToTensor(),\n",
    "                     Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "images = ImageFolder(folder, transform=transform)\n",
    "image, label = images[0]\n",
    "print(\"Type of image is now:\", type(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function inverts the transformation of the input images.\n",
    "def to_image(tensor):\n",
    "    tensor = 0.5 * (tensor + 1.0)\n",
    "    return to_pil_image(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training, we further split the data into training and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(0.9 * len(images))\n",
    "n_val = len(images) - n_train\n",
    "training_data, validation_data = torch.utils.data.random_split(images, (n_train, n_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exercise 2: Training a fully-connected network, 5 points]\n",
    "## Defining a neural network model\n",
    "\n",
    "Neural networks in `pytorch` are represented using the [`torch.nn.Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) class. The typical way to define a neural network model is to define a new class that inherits from the `Module` class.\n",
    "\n",
    "### 2, a) (2 points)\n",
    "\n",
    "Inspect the code given below and, using the documentation of the [`torch.nn`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) module, answer the following questions:\n",
    "- What is the architecture of instances of the `FullyConnected` class?\n",
    "- What activations functions are applied in the hidden layers?\n",
    "- What activation function is used for the output?\n",
    "- How are the parameters of the network initialized? Why is this important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FullyConnected(nn.Module):\n",
    "    \"\"\"\n",
    "    Usually, this docstring should contain useful information about this\n",
    "    class but this would make the exercise too easy.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_features,\n",
    "                 width):\n",
    "        \"\"\"\n",
    "        Create a new mysterious network.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_features = input_features\n",
    "        self.fc_1 = nn.Linear(input_features, width)\n",
    "        self.fc_2 = nn.Linear(width, width)\n",
    "        self.fc_3 = nn.Linear(width, width)\n",
    "        self.fc_4 = nn.Linear(width, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The forward method required by nn.Module base class.\n",
    "        \"\"\"\n",
    "        x = x.flatten(1, -1)\n",
    "        x = self.fc_1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc_3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc_4(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training loop\n",
    "\n",
    "In the cell below you find code for a typical training loop in `pytorch`. \n",
    "\n",
    "### 2, b) (1 point)\n",
    "\n",
    "Look at the function below. Most of the actual training functionality is abstracted away in the arguments provided to the function. For each of the arguments, describe what tasks the corresponding object has to perform so that this method can be used to train a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(training_loader,\n",
    "                validation_loader,\n",
    "                model,\n",
    "                loss,\n",
    "                optimizer,\n",
    "                device):\n",
    "    \"\"\"\n",
    "    Again, this should be a useful docstring, but that would\n",
    "    give away the answer for the exercise.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    training_loss = 0.0\n",
    "    n = len(training_loader)\n",
    "    \n",
    "    for i, (x, y) in enumerate(training_loader):\n",
    "        \n",
    "        # Set gradients to zero.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Move input to device\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Predict output, compute loss, perform optimizer step.\n",
    "        y_pred = model(x)\n",
    "        l = loss(y_pred, y.view(-1, 1).float())\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss += l.item()\n",
    "        print(\"Batch ({} / {}): Loss {:.2f}\".format(i, n, l.item()), end=\"\\r\")\n",
    "        \n",
    "    training_loss /= n\n",
    "        \n",
    "    model.eval()\n",
    "    validation_loss = 0.0\n",
    "    n = len(validation_loader)\n",
    "    \n",
    "    for i, (x, y) in enumerate(validation_loader):\n",
    "        # Move input to device\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Predict output, compute loss, perform optimizer step.\n",
    "        y_pred = model(x)\n",
    "        l = loss(y_pred, y.view(-1, 1).float())\n",
    "        \n",
    "        validation_loss += l.item()\n",
    "    validation_loss /= n\n",
    "    \n",
    "    model.to(torch.device(\"cpu\"))\n",
    "    \n",
    "    return (training_loss, validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The optimizer object\n",
    "\n",
    "In the code above the optimization method was hidden in the `optimizer` object. To understand how to write a suitable optimizer, you first need to understand a bit more about the role of `Module` objects in `pytorch`. The `torch.nn.Module` class is the base class for all neural networks and the components that make up neural networks. Module objects typically have trainable parameters. These trainable parameters of a module can be accessed via its `parameters()` member function. When a module contains attributes that are themselves `Module` instances, then  the `parameters()` function of the containing module will automatically list the trainable parameters of its `Module` attributes.\n",
    "\n",
    "In order to  train a network, the optimizer needs to be aware of the module's parameters. In `pytorch` an optimizer object therefore always needs to be instantiated with a list of parameters that should be trained. In addition to that, an optimizer typically provides a function to set the gradients of the module parameters to zero. This is because gradients in pytorch are accumulated between consecutive calls to the `backward()` function.\n",
    "This makes it necessary to set the gradients to zero between to training iterations.\n",
    "\n",
    "### 2, c)  (0.5 points)\n",
    "\n",
    "Complete the code below so that the `step` method of the `SGD` class performs gradient descent on the provided list of parameters.\n",
    "\n",
    "> **Hint 1:** The `parameters()` member function returns a list of tensors representing the weight matrices and bias vectors in a network. Given a tensor `p`, you can access its gradients using the `p.grad` attribute.\n",
    "\n",
    "> **Hint 2:** Because of the way `pytorch`'s autograd function works, changing the  value of a parameter `p` has to be done using its `p.data` attribute:\n",
    "\n",
    "```\n",
    "p.data = ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent():\n",
    "    \"\"\"\n",
    "    A gradient descent optimizer.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 parameters,\n",
    "                 learning_rate):\n",
    "        \"\"\"\n",
    "        Create a gradient descent optimizer.\n",
    "        \n",
    "        Arguments:\n",
    "            parameters: Iterable providing the parameters to optimize.\n",
    "            learning_rate: The learning rate to use for optimization.\n",
    "        \"\"\"\n",
    "        self.parameters = list(parameters)\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters:\n",
    "            if not p.grad is None:\n",
    "                p.grad.zero_()\n",
    "        \n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Perform a gradient descent step on parameters associated to this optimizer.\n",
    "        \"\"\"\n",
    "        for p in self.parameters:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "With the optimizer, the model and the training loop in place we are close to being able to start training the network, however a few details remain to be sorted out.\n",
    "\n",
    "The `training_data` and `validation_data` object defined above can be used to iterate over the data, but only on a per sample basis. For the training a neural network, however, we typically want to iterate through the data in batches. To take care of this , `pytorch` provides the `DataLoader` class, which can be used to batch and shuffle existing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch.utils.data import DataLoader\n",
    "training_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(validation_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to choose a suitable training loss to minimize.\n",
    "\n",
    "### 2, d) (0.5 points)\n",
    "\n",
    "Choose a suitable loss function from the [`torch.nn`](https://pytorch.org/docs/stable/nn.html) module and assign an instance of it to the loss variable in the code cell below\n",
    "\n",
    "> **Hint:** Note that in the `train_epoch` function defined above loss function is applied **directly** to the output of the network. In your choice of the loss function you thus need to consider the output activation of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we choose the device to run the training on. If available, you should use a GPU because it will be substantially faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = cuda\n",
    "else:\n",
    "    device = cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2, e) (1 point)\n",
    "\n",
    "Train the neural network for a least 10 epochs, then reduce the learning rate and continue training for at least another ten epochs. Plot the resulting training and validation losses. Was the training successful?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exercise 3: Training on augmented training data, 3 points]\n",
    "\n",
    "If you trained the model long enough, you should see that the model overfits on the training data, which \n",
    "causes the generalization error to increase.  This is not surprising considering that the training set is rather small. A technique to counteract overfitting is to augment the training data by artificially increasing the size of the training data set. In this case we will use random transforms that mimic the effect of perspective or changes in lighting to the images.\n",
    "\n",
    "### 3, a) (1 point)\n",
    "\n",
    "Create an augmented training data set by adding suitable transforms from the [`torchvision.transforms`](https://pytorch.org/docs/stable/torchvision/transforms.html) module to the transformations that are applied when\n",
    "the images are loaded. Suitable transforms to consider are `RandomAffine` and `ColorJitter`.\n",
    "\n",
    "> **Hint**: Applying these transforms of course only makes sense for the training data and not the validation\n",
    " data. To ensure that this is the case do not create new `training_data` and `validation_data` objects but instead overwrite the `training_data.dataset` attribute of the existing `training_data` object, as shown below. (This is a bit hacky, but the easiest way to achieve this in the current context.)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_augmented = ... # Define augmented data\n",
    "\n",
    "training_data.dataset = dataset_augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a preview of the augmented training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, 4, figsize=(8, 2))\n",
    "for i in range(4):\n",
    "    ax = axs[i]\n",
    "    ax.imshow(to_image(images_augmented[0][0]))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3, b) (1 point)\n",
    "\n",
    "Train the fully-connected model once again on the augmented training data. You should achieve a validation loss lower than 0.6. Plot training and validation loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3, c) (1 point)\n",
    "\n",
    "A useful performance metric for binary classification tasks  is the [receiver operating characteristic (ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic). Complete the code below and write a function that computes the true positive and false positive rate for varying values of the discrimination threshold $p \\in [0, 1]$. Then, using the code below, plot the ROC. What is the significance of the line black, dashed line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def receiver_operating_characteristic(model,\n",
    "                                      validation_loader,\n",
    "                                      ps):\n",
    "    \"\"\"\n",
    "    Computes receiver operating characteristic for given model and\n",
    "    validation data.\n",
    "    \n",
    "    Arguments:\n",
    "        model: The pytorch model to evaluate.\n",
    "        validation_loader: torch DataLoader to use to iterate over validation data.\n",
    "        ps: Iterable containing the values of the discrimination threshold in\n",
    "           increasing order.\n",
    "    Returns:\n",
    "        (fpr, tpr): Tuple containing the false positive rates (fpr) and the true\n",
    "            positive rates as numpy.ndarrays.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr = receiver_operating_characteristic(fc, validation_loader, np.linspace(0, 1, 101))\n",
    "\n",
    "# Plot ROC curve\n",
    "x = np.linspace(0, 1, 101)\n",
    "f, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, x, c=\"k\", ls=\"--\")\n",
    "ax.plot(fpr, tpr)\n",
    "ax.set_ylabel(\"TPR\")\n",
    "ax.set_xlabel(\"FPR\")\n",
    "ax.set_title(\"Receiver operator characteristic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at the prediction for samples from the validation set. On average, your model should get more images right than wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_pet(index):\n",
    "    \n",
    "    if index == 0:\n",
    "        return \"cat\"\n",
    "    else:\n",
    "        return \"dog\"\n",
    "    \n",
    "def plot_results(model, validation_data):\n",
    "    model.to(torch.device(\"cpu\"))\n",
    "    f, axs = plt.subplots(2, 5, figsize=(10, 4))\n",
    "    for i in range(10):\n",
    "\n",
    "        # Make prediction on random validation sample\n",
    "        index = np.random.randint(len(validation_data))\n",
    "        x, y = validation_data[index]\n",
    "        c = torch.sigmoid(model(x.unsqueeze(0))) >= 0.5\n",
    "        x = 0.5 * (x + 1.0)\n",
    "        \n",
    "        ax = axs.ravel()[i]\n",
    "        ax.imshow(to_pil_image(x))\n",
    "        title = \"Predicted '{}', \\n True '{}'\"\n",
    "        title = title.format(index_to_pet(c), index_to_pet(y))\n",
    "        ax.set_title(title)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "        \n",
    "plot_results(fc, validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exercise 4: Training a convolutional  neural network, 4 points]\n",
    "\n",
    "### 4, a) (2 points)\n",
    "\n",
    "Define and train a convolutional network with the following architecture:\n",
    "- 2D conv. layer: $32$ filters, kernel size $5 \\times 5$, stride 1\n",
    "- ReLU activation function\n",
    "- Max pooling: kernel size $4 \\times 4$, stride 4\n",
    "- 2D conv. layer: $64$ filters, kernel size $5 \\times 5$, stride 1\n",
    "- ReLU activation function\n",
    "- Max pooling: kernel size $2 \\times 2$, stride 2\n",
    "- 2D conv. layer: $128$ filters, kernel size $3 \\times 3$, stride 1\n",
    "- ReLU activation function\n",
    "- Max pooling: kernel size $2 \\times 2$, stride 2\n",
    "- Fully connected: 512 neurons\n",
    "- ReLU activation function\n",
    "- Fully connected: 512 neurons\n",
    "    \n",
    "With this architecture, you should achive a validation loss below $0.3$. \n",
    "\n",
    "> **Hint:** You can find all necessary components to implement the convolutional network in the [`torch.nn`](https://pytorch.org/docs/stable/nn.html) module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4, a)  (2 points)\n",
    "\n",
    "Tune the network architecture and training routin to achieve a validation error lower than 0.15 on the validation set. Some things you may want to try:\n",
    "- Increasing the complexity of your network (more layers, filters or neurons)\n",
    "- A learning rate schedule\n",
    "- Checkpoints or early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exercise 5: Evaluation on test set, 2 points]\n",
    "\n",
    "Now evaluate the performance of the fully-connected neural network to your best convolutional neural network on the `catsndogs` test data, which is available in `catsndogs.test` module.\n",
    "\n",
    "- Plot ROC curves for both the fully-connected and the convolutional model.\n",
    "- Compute the accuracy of each model for a discimination threshold p = 0.5\n",
    "- Provide a plot of 8 images from the test set together with the prediction from the convolutional model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Exercise 6 (Bonus*): Your algorithm in the wild, 2 points]\n",
    "\n",
    "Acquire an image of a cat or dog resize it to size $128 \\times 128$ pixels and apply your model to it. Present your results. Does it work?\n",
    "\n",
    "\n",
    "*: This is bonus exercise and will give you two point that can make up for a point lost somewhere in the assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
